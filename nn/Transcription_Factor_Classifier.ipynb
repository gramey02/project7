{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b4d2d52-e5e5-4a88-806f-d113628085b5",
   "metadata": {},
   "source": [
    "# Transcription Factor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b054ee10-df30-48b7-a4d1-82b8e1b22236",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn import NeuralNetwork\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Union\n",
    "from numpy.typing import ArrayLike\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from TFC_io import read_text_file, read_fasta_file\n",
    "from preprocess import sample_seqs, one_hot_encode_seqs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee1fc43-7596-4d78-bbb0-44027f8a6673",
   "metadata": {},
   "source": [
    "### Read in Rap1 motif examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc241a21-3b83-48bc-bbb0-cd7438b0d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rap1_motifs = read_text_file(\"../data/rap1-lieb-positives.txt\")\n",
    "labels = [True for i in range(len(rap1_motifs))] #generate labels, where True = positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503309a4-3098-4d45-8b27-9c4f428d8894",
   "metadata": {},
   "source": [
    "### Read in negative example from yeast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45616f58-f609-4158-9176-fec59944bd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "yeast_neg = read_fasta_file(\"../data/yeast-upstream-1k-negative.fa\")\n",
    "labels = labels + [False for i in range(len(yeast_neg))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aea433-a9c4-43e2-9ba6-2a65bb21d282",
   "metadata": {},
   "source": [
    "### Explain Sampling Scheme\n",
    "I chose to use oversampling to correct the class imbalance in the data by resampling the positive class with replacement until it had the same number of observations as the negative class. While this can make the classification model prone to ovefitting, it prevents information loss and avoids an extremely small sample size if we were to downsample the yeast data to the size of the rap1_motifs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441c939f-3bfd-46bf-8388-7344c03d6366",
   "metadata": {},
   "source": [
    "### Implement sampling scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3869fdb-f20e-44a9-9d19-c10aa8df2005",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = rap1_motifs + yeast_neg #combine the two lists of seqs\n",
    "new_seqs, new_labels = sample_seqs(seqs, labels) #fix class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9310c5-b0b6-406e-b878-39b86f2fa900",
   "metadata": {},
   "source": [
    "### Generate training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db8d5c66-2ce4-4cf9-822b-286724f7014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use a 70/30 train/test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(new_seqs, new_labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79975b2-609a-4978-a697-215574221662",
   "metadata": {},
   "source": [
    "### One hot encode the sequences in the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be96314e-f2d8-4e19-972b-2f21bd9dbd2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4428,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d364aecab4df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_encode_seqs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_val_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_encode_seqs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4428,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "X_train_encoded = np.array(one_hot_encode_seqs(X_train), dtype = float)\n",
    "X_val_encoded = np.array(one_hot_encode_seqs(X_val), dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31078b4b-8ef7-472c-984d-9bd686b9f777",
   "metadata": {},
   "outputs": [],
   "source": [
    "lol = [[1,2,3],\n",
    "      [4,5,6]]\n",
    "\n",
    "np.array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef360f5-9ca3-429e-8a03-642105cfa7f4",
   "metadata": {},
   "source": [
    "### Define plotting function so loss history of neural network can be visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c5e86ff-e089-410f-aaee-587fccf904cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_history(per_epoch_loss_train, per_epoch_loss_val):\n",
    "    \"\"\"\n",
    "    Plots the loss history after training is complete.\n",
    "    \"\"\"\n",
    "    loss_hist = per_epoch_loss_train\n",
    "    loss_hist_val = per_epoch_loss_val\n",
    "    assert len(loss_hist) > 0, \"Need to run training before plotting loss history\"\n",
    "    fig, axs = plt.subplots(2, figsize=(8,8))\n",
    "    fig.suptitle('Loss History')\n",
    "    axs[0].plot(np.arange(len(loss_hist)), loss_hist)\n",
    "    axs[0].set_title('Training Loss')\n",
    "    axs[1].plot(np.arange(len(loss_hist_val)), loss_hist_val)\n",
    "    axs[1].set_title('Validation Loss')\n",
    "    plt.xlabel('Steps')\n",
    "    axs[0].set_ylabel('Train Loss')\n",
    "    axs[1].set_ylabel('Val Loss')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596489c5-3ee4-4ea8-8318-b05fcf101c1a",
   "metadata": {},
   "source": [
    "### Train a neural network\n",
    "I will be exploring some hyperparameters in the next few code chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df066119-6905-4477-88c4-87255a6362d7",
   "metadata": {},
   "source": [
    "Number of hidden layers = 1, hidden layer activation function = relu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "928c5bc8-96fc-4b9d-a8e4-2979d14b4a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start with a neural network with only 1 hidden layer with 5 nodes and go from there (final output should stem from a sigmoid function)\n",
    "nn_arch = [{'input_dim': 1, 'output_dim': 5, 'activation': 'sigmoid'}, \n",
    "           {'input_dim': 5, 'output_dim': 1, 'activation': 'sigmoid'}]\n",
    "classifier = NeuralNetwork(nn_arch, \n",
    "                          lr=0.1, \n",
    "                          seed=42, \n",
    "                          batch_size=15, \n",
    "                          epochs=100, \n",
    "                          loss_function = \"binary cross entropy\")\n",
    "#make sure to expand the dimensions of the input data and convert both input and output data to arrays\n",
    "X_train_encoded = np.expand_dims(np.array(X_train_encoded),axis=1)\n",
    "X_val_encoded = np.expand_dims(np.array(X_val_encoded),axis=1)\n",
    "y_train = np.array(np.expand_dims(y_train,axis=1))\n",
    "y_val = np.array(np.expand_dims(y_val,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f80564c3-b888-4523-ba7c-f9c9d479e786",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-41baa9b77519>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#fit the neural network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/UCSF/Algorithms/project7/nn/nn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                 \u001b[0;31m#forward pass through the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m                 \u001b[0;31m#calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss_func\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"mean squared error\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/UCSF/Algorithms/project7/nn/nn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mb_curr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#get current bias terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mA_curr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ_curr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_single_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_curr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_curr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_activation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA_curr\u001b[0m \u001b[0;31m#store current A matrix in cache dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/UCSF/Algorithms/project7/nn/nn.py\u001b[0m in \u001b[0;36m_single_forward\u001b[0;34m(self, W_curr, b_curr, A_prev, activation)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mA_prevT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mZ_curr_noT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_curr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_prevT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_curr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mZ_curr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_curr_noT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#dimensions = n_observations x # output neurons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "source": [
    "#fit the neural network\n",
    "classifier.fit(X_train_encoded, y_train, X_val_encoded, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8aeb0b0b-00c9-4d4d-a78a-38f51592f960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af0991b8-1ccb-4c67-8f8f-84d3ad4e516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array([[1,2,3],\n",
    "                [4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab2b6cac-e474-4362-b872-2cb4866ca4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20048212-eb0b-4f92-8160-8a3efa2b644e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
